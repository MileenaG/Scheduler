{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File needs to be in the correct format and have the right columns\n",
    "This code is to get probabilities from file [NearGalCat or GW_Query],then we make manual cuts to the file. We keep only the targets with the highest probability, then we calculate the dust and add a dust column. Then we make cuts to the file. Anything bigger than 0.5 we delete. Then we manually add a priority column which is the inverse of the probability and lastly add, using code, the Type, Exposure Time, and absolute magnitude. Also the aparent magnitude and 2D probability columns were deletd in the final file. Not sure if we will need them to calculate dynamic exposures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import json\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import csv\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takes HEALPix file and converts it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSIDE = 256\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "Ordering converted to RING\n",
      "Ordering converted to RING\n",
      "Ordering converted to RING\n",
      "Ordering converted to RING\n",
      "('XTENSION', 'BINTABLE')\n",
      "('BITPIX', 8)\n",
      "('NAXIS', 2)\n",
      "('NAXIS1', 16384)\n",
      "('NAXIS2', 768)\n",
      "('PCOUNT', 0)\n",
      "('GCOUNT', 1)\n",
      "('TFIELDS', 4)\n",
      "('TTYPE1', 'PROB')\n",
      "('TFORM1', '1024E')\n",
      "('TUNIT1', 'pix-1')\n",
      "('TTYPE2', 'DISTMU')\n",
      "('TFORM2', '1024E')\n",
      "('TUNIT2', 'Mpc')\n",
      "('TTYPE3', 'DISTSIGMA')\n",
      "('TFORM3', '1024E')\n",
      "('TUNIT3', 'Mpc')\n",
      "('TTYPE4', 'DISTNORM')\n",
      "('TFORM4', '1024E')\n",
      "('TUNIT4', 'Mpc-2')\n",
      "('PIXTYPE', 'HEALPIX')\n",
      "('ORDERING', 'NESTED')\n",
      "('COORDSYS', 'C')\n",
      "('EXTNAME', 'xtension')\n",
      "('NSIDE', 256)\n",
      "('FIRSTPIX', 0)\n",
      "('LASTPIX', 786431)\n",
      "('INDXSCHM', 'IMPLICIT')\n",
      "('OBJECT', '0')\n",
      "('DATE-OBS', '2017-01-04T10:11:58.600292')\n",
      "('MJD-OBS', 57757.42498379962)\n",
      "('DATE', '2017-01-06T16:37:42.000000')\n",
      "('CREATOR', 'run_sky_area')\n",
      "('DISTMEAN', 922.3304700403676)\n",
      "('DISTSTD', 258.1090838196292)\n"
     ]
    }
   ],
   "source": [
    "# ColDefs(\n",
    "#     name = 'PROB'; format = '1024E'; unit = 'pix-1'\n",
    "#     name = 'DISTMU'; format = '1024E'; unit = 'Mpc'\n",
    "#     name = 'DISTSIGMA'; format = '1024E'; unit = 'Mpc'\n",
    "#     name = 'DISTNORM'; format = '1024E'; unit = 'Mpc-2'\n",
    "# )\n",
    "\n",
    "hpx_file = 'LALInference_skymap.fits.gz,3'\n",
    "# prob, header = hp.read_map(hpx_file, h=True)\n",
    "\n",
    "# hpx_file = 'bayestar.fits.gz'\n",
    "prob, distmu, distsigma, distnorm, header = hp.read_map(hpx_file, field=(0,1,2,3), h=True)\n",
    "\n",
    "for h in header:\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky Area per pix: 0.052455852825697924\n",
      "Resolution (nside): 256\n"
     ]
    }
   ],
   "source": [
    "# prob, distmu, distsigma, distnorm, header = hp.read_map(hpx_file, field=(0,1,2,3), h=True)\n",
    "\n",
    "# Degrees per pixel\n",
    "npix = len(prob)\n",
    "sky_area = 4 * 180**2 / np.pi\n",
    "print(\"Sky Area per pix: %s\" % (sky_area / npix))\n",
    "\n",
    "# nside = the lateral resolution fo the HEALPix map\n",
    "nside = hp.npix2nside(npix)\n",
    "print(\"Resolution (nside): %s\" % nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validFloat(i):   \n",
    "    valid = True\n",
    "    try:\n",
    "        float(i)\n",
    "    except ValueError:\n",
    "        valid = False\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"GW_Query.csv\",\"r\") as csvinput:                   #input file \n",
    "    with open(\"GW_Resolved.csv\",\"w\") as csvoutput:  #output file-goes int he same folder as input file \n",
    "        \n",
    "                reader = csv.reader(csvinput, delimiter=\",\")\n",
    "                writer = csv.writer(csvoutput, lineterminator=\"\\n\")     #RENAME FILES!!\n",
    "\n",
    "                output_rows = []\n",
    "                header_row = next(reader)\n",
    "                header_row.append(\"Prob\")\n",
    "                header_row.append(\"DistMu\")\n",
    "                header_row.append(\"DistSigma\")\n",
    "                header_row.append(\"DistNorm\")\n",
    "                header_row.append(\"TotalSigma\")\n",
    "                header_row.append(\"z-Prob\")\n",
    "                header_row.append(\"3D-Prob\")\n",
    "                output_rows.append(header_row)\n",
    "\n",
    "                # Remaing rows\n",
    "                for row in reader:\n",
    "\n",
    "                    ra = row[0] # RA (degree) col\n",
    "                    dec = row[1] # DEC (degree) col\n",
    "                    c = coord.SkyCoord(ra+dec,unit=(u.hourangle, u.deg),frame=\"fk5\")\n",
    "\n",
    "                    # Convert to spherical polar coords\n",
    "                    theta = 0.5 * np.pi - np.deg2rad(c.dec.degree)\n",
    "                    phi = np.deg2rad(c.ra.degree)\n",
    "\n",
    "                    # Resolve RA, DEC => Pixel\n",
    "                    px = hp.ang2pix(nside, theta, phi)\n",
    "\n",
    "                    # Get corresponding HEALPIX quantities\n",
    "                    p = prob[px]\n",
    "                    du = distmu[px] \n",
    "                    ds = distsigma[px]\n",
    "                    dn = distnorm[px]\n",
    "\n",
    "                    row.append(p)\n",
    "\n",
    "                    row.append(du)\n",
    "                    row.append(ds)\n",
    "                    row.append(dn)\n",
    "\n",
    "                    # Compute composite probabilities\n",
    "                    if (validFloat(row[18]) and validFloat(row[19])):\n",
    "\n",
    "                        galaxy_distance = float(row[18])\n",
    "                        galaxy_distance_err = float(row[19])\n",
    "\n",
    "                        if (galaxy_distance > 0 and galaxy_distance_err > 0):\n",
    "                            sigmaTotal = np.abs(galaxy_distance - du)/np.sqrt(galaxy_distance_err**2 + ds**2)\n",
    "                            zProb = 1-erf(sigmaTotal)\n",
    "                            threeDProb = p * zProb\n",
    "\n",
    "                            row.append(sigmaTotal)\n",
    "                            row.append(zProb)\n",
    "                            row.append(threeDProb)\n",
    "\n",
    "                            output_rows.append(row)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                writer.writerows(output_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my memory we took output file renamed it (maybe also moves it out of folder it is currently in) and made the following cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we make manual cuts by 3D Probability to 20170314_GW_Resolved.csv file. Want code that does this. Want top 3000\n",
    "\n",
    "## Priority=1/3D Probability  (do this manually) \n",
    " lowest number is highest the priority "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a good chunk of the data the probability is 0 (Delete these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astroquery.irsa_dust import IrsaDust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: fix code to take like 1000 at a time and run thru those and ass dust column and remove ones that have grater than 0.5 dust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_csv.reader' object has no attribute 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b364e49e045a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvinput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvoutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1000\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_csv.reader' object has no attribute 'csv'"
     ]
    }
   ],
   "source": [
    "with open(\"20170314_GW_Resolved_TopProb.csv\",\"r\") as csvinput:       #this file has 3000 targets\n",
    "    with open(\"20170314_GW_Resolved_TopProb_dust.csv\",\"w\") as csvoutput:\n",
    "        \n",
    "        reader = csv.reader(csvinput, delimiter=\",\")\n",
    "        writer = csv.writer(csvoutput, lineterminator=\"\\n\")\n",
    "        read.csv(reader, nrows=\"1000\")\n",
    "        \n",
    "        output_rows = []\n",
    "        header_row = next(reader)\n",
    "        header_row.append(\"Av\")\n",
    "        \n",
    "        output_rows.append(header_row)\n",
    "        \n",
    "        for row in reader:\n",
    "            ra = row[0] # RA (degree) col\n",
    "            dec = row[1] # DEC (degree) col\n",
    "            c = coord.SkyCoord(ra+dec,unit=(u.hourangle, u.deg),frame=\"fk5\")\n",
    "            \n",
    "            dust_table = IrsaDust.get_extinction_table(c)\n",
    "            av = dust_table[\"A_SandF\"][np.where(dust_table[\"Filter_name\"] == \"CTIO V\")][0]\n",
    "            row.append(av)\n",
    "            output_rows.append(row)\n",
    "\n",
    "        writer.writerows(output_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_JN2R24_22367/DUST/338.8641666666666_-9.368333333333334.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_SsIDN2_22385/DUST/338.9_-9.374722222222223.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_SplRkK_22403/DUST/338.435_-8.834444444444447.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_PIATvO_22430/DUST/338.77833333333325_-8.764444444444447.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_5eOfBy_22448/DUST/338.7791666666666_-8.76527777777778.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_kpbmTn_22475/DUST/339.8945833333333_-9.37138888888889.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_DtzUBj_22493/DUST/337.8904166666666_-8.704722222222221.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_gEr4T8_22520/DUST/337.23958333333326_-6.937777777777778.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_gwOmCV_22538/DUST/339.3383333333333_-8.46111111111111.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_N6rwRM_22557/DUST/339.95666666666665_-8.38972222222222.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_ftJ2oO_22583/DUST/339.3420833333333_-8.462499999999999.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_WIiiqZ_22610/DUST/339.8545833333333_-8.766111111111114.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_N3p3dW_22628/DUST/341.5154166666666_-11.001111111111111.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_GctBv4_22655/DUST/341.94875_-11.816666666666668.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_oJrUhS_22673/DUST/146.82625_72.98416666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_r8zflM_22694/DUST/146.81083333333333_72.9863888888889.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_TJBoKH_22720/DUST/146.95999999999998_72.96444444444445.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_mOoKYV_22747/DUST/340.3941666666667_-8.807222222222224.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_GEihA5_22787/DUST/342.13541666666663_-11.977777777777778.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_gihOL3_22805/DUST/153.88416666666666_74.22027777777778.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_N3OCuN_22832/DUST/342.8883333333333_-11.931666666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_ywQFKO_22850/DUST/146.6966666666667_72.45055555555555.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_4elwxz_22877/DUST/137.11541666666668_50.564166666666665.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_Z1U8Xn_22895/DUST/147.5925_72.27916666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_fln2D9_22913/DUST/137.89_51.254444444444445.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_TwjeAx_22987/DUST/104.97375_-0.4241666666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_UaKn2f_23065/DUST/105.02208333333333_-2.3977777777777773.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_RB0pkv_23112/DUST/137.41666666666666_49.99583333333334.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_rTXiYx_23130/DUST/104.32541666666665_-5.066666666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_Zqkh7Z_23158/DUST/104.51166666666666_-5.344722222222222.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_aImno5_23185/DUST/154.41625_74.3475.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_QxOOho_23203/DUST/162.16291666666666_76.80388888888889.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_Ojp0Pl_23230/DUST/161.97458333333333_76.84694444444445.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_WtZYfo_23249/DUST/107.66875_6.453888888888888.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_B2Glbh_23276/DUST/107.79875000000001_6.318333333333333.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_CpjSvD_23305/DUST/106.40083333333332_5.4047222222222215.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_fq2wkB_23332/DUST/139.4433333333333_53.29277777777778.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_cAcHLw_23353/DUST/139.44708333333332_53.29361111111111.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_lzbr2s_23408/DUST/139.4175_52.993611111111115.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_4GcFJw_23427/DUST/137.54958333333332_50.40138888888889.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_Qa488D_23467/DUST/137.3875_50.281666666666666.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_hMIfsG_23485/DUST/137.47708333333333_50.41833333333333.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_plUCAv_23513/DUST/341.0_-10.116944444444444.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_JE27Yy_23533/DUST/139.00958333333332_52.84.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_bHNkVs_23565/DUST/162.68875_76.93722222222223.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_5cRb9m_23583/DUST/104.09041666666666_-3.7216666666666662.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_RSuTL8_23607/DUST/103.32624999999999_-3.8666666666666667.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_B46nm5_23628/DUST/103.27166666666665_-3.9747222222222223.v0001/extinction.tbl [Done]\n",
      "Downloading https://irsa.ipac.caltech.edu:443//workspace/TMP_nWmLFT_23646/DUST/147.95833333333334_72.08333333333333.v0001/extinction.tbl [Done]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Top50_3DProb.csv\",\"r\") as csvinput:       #this file has 3000 targets #GW_Resolved_TopProb.csv\n",
    "    with open(\"Top50_TopProb_dust.csv\",\"w\") as csvoutput:\n",
    "        \n",
    "        reader = csv.reader(csvinput, delimiter=\",\")\n",
    "        writer = csv.writer(csvoutput, lineterminator=\"\\n\")\n",
    "        \n",
    "        output_rows = []\n",
    "        header_row = next(reader)\n",
    "        header_row.append(\"Av\")\n",
    "        \n",
    "        output_rows.append(header_row)\n",
    "        \n",
    "        for row in reader:\n",
    "            ra = row[0] # RA (degree) col\n",
    "            dec = row[1] # DEC (degree) col\n",
    "            c = coord.SkyCoord(ra+dec,unit=(u.hourangle, u.deg),frame=\"fk5\")\n",
    "            \n",
    "            dust_table = IrsaDust.get_extinction_table(c)\n",
    "            av = dust_table[\"A_SandF\"][np.where(dust_table[\"Filter_name\"] == \"CTIO V\")][0]\n",
    "            row.append(av)\n",
    "            output_rows.append(row)\n",
    "\n",
    "        writer.writerows(output_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take top targets that have dust less than 0.5 from file 20170314_GW_Resolved_TopProb_dust.csv.... again manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm \n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import Angle\n",
    "from cycler import cycler\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from itertools import map\n",
    "except ImportError:\n",
    "    # Python 3...\n",
    "    imap=map\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Top50_Dust.csv', 'r') as input_file:\n",
    "     with open('Top50_DustCut.csv', 'w') as output_file:\n",
    "        reader = csv.reader(input_file, delimiter=\",\")\n",
    "        writer = csv.writer(output_file, lineterminator=\"\\n\")\n",
    "            \n",
    "        writer.writerows(imap(itemgetter(3, 0, 1, 26, 18), reader)) #reorganizes the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Top50_DustCut.csv', 'r') as csvinput:\n",
    "    with open('GW_Resolved_TopProb_TopDust_Mag.csv', 'w') as csvoutput:\n",
    "            \n",
    "        reader = csv.reader(csvinput, delimiter=\",\")   \n",
    "        writer = csv.writer(csvoutput, lineterminator=\"\\n\")\n",
    "        \n",
    "        output_rows = []\n",
    "        header_row = next(reader)                    #This is adding the apparent Mag and Date columns\n",
    "        header_row.append(\"App_Mag\")\n",
    "        header_row.append(\"Disc_Date\")      #add types, static exposure time, absolute magnitude\n",
    "        header_row.append(\"Type\") \n",
    "        header_row.append(\"SET\")\n",
    "        header_row.append(\"EstAbsMag\") \n",
    "        output_rows.append(header_row)\n",
    "        \n",
    "        for row in reader:\n",
    "            row.append(18.)              #Mag 18\n",
    "            row.append(20170314)         #Date\n",
    "            row.append(\"GWS\")\n",
    "            row.append(10)\n",
    "            row.append(18)\n",
    "            \n",
    "            output_rows.append(row)\n",
    "\n",
    "        writer.writerows(output_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "make code that adds the type, exposure time, and absolute magnitude columns.\n",
    "Manually calculate priority which is the inverse of the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\tnames = [t[0] for t in target_data]\n",
    "\tra = [t[1] for t in target_data]\n",
    "\tdec = [t[2] for t in target_data]\n",
    "\tpriorities = [float(t[3]) for t in target_data]         \n",
    "\tdisc_dates = [t[4] for t in target_data]\n",
    "\tdisc_mags = [float(t[5]) for t in target_data] \n",
    "\ttypes = [t[6] for t in target_data]                        \n",
    "\tstatic_exposure_time = [float(t[7]) for t in target_data]\n",
    "\tEstAbsMag = [float(t[8]) for t in target_data]    #assuing they're 18\n",
    "\tdist_Mpc = [float(t[9]) for t in target_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TRY RUNNING SCHEDULER WITH NICKEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
